{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:18:44.928567600Z",
     "start_time": "2024-05-12T20:18:35.223200200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from birdsong_dataset import AudioDataset"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "file_id                   3\ngenus                     1\nspecies                   1\nenglish_cname             1\nwho_provided_recording    2\ncountry                   2\nlatitude                  2\nlongitute                 2\ntype                      3\nlicense                   2\ndtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/birdsong_metadata_test.csv\")\n",
    "df.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:18:48.118749Z",
     "start_time": "2024-05-12T20:18:48.040746600Z"
    }
   },
   "id": "f83f194f40a936d8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2 as cv\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, name , species = sample[0], sample[1],sample[2]\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(image) , torch.from_numpy(name) , torch.from_numpy(species)\n",
    "    \n",
    "class ToTensor_noise_red(object):\n",
    "    def __call__(self, sample):\n",
    "        image, name , species = sample[0], sample[1],sample[2]\n",
    "\n",
    "        # image = cv.medianBlur(image,)\n",
    "        # image = image.astype(np.uint8)\n",
    "        image = cv.erode(image , kernel= (7,7) , iterations=3)\n",
    "        # ret3,image = cv.threshold(image,0,255, cv.ADAPTIVE_THRESH_MEAN_C)\n",
    "        image = image.reshape((image.shape[0] , image.shape[1] , 1)).transpose((2, 0, 1))\n",
    "        return torch.from_numpy(image) , torch.from_numpy(name) , torch.from_numpy(species)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:30:16.747358100Z",
     "start_time": "2024-05-12T20:30:16.538240100Z"
    }
   },
   "id": "fa42b2e5f18218a1",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading The Data...\n",
      "Data Loaded !\n"
     ]
    }
   ],
   "source": [
    "# dataset_noisy = AudioDataset(metadata_path= \"data/birdsong_metadata_test.csv\"  , transform = ToTensor(), max_len= 3 , overlapping = 0.5 , noise_reduction=False)\n",
    "dataset = AudioDataset(metadata_path= \"data/birdsong_metadata.csv\"  , transform = ToTensor_noise_red(), max_len= 3 , overlapping = 0.5 , noise_reduction=True, noise_reduction_level=0.95)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:35:11.444761100Z",
     "start_time": "2024-05-12T20:30:55.033392700Z"
    }
   },
   "id": "e88c6582f2915956",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# plt.figure(figsize=(10,20))\n",
    "# counter = 1\n",
    "# for i in range(4):\n",
    "#     for j in range(2):\n",
    "#         plt.subplot(4,2,counter)\n",
    "#         counter+=1\n",
    "#         plt.title(dataset[i][1].item())\n",
    "#         if j % 2 == 0 :\n",
    "#             plt.imshow(dataset[i][0].to('cpu').numpy().transpose((1,2,0)) , cmap = \"grey\")\n",
    "#         else:\n",
    "#             plt.imshow(dataset_noisy[i][0].to('cpu').numpy().transpose((1,2,0)),  cmap = \"grey\")\n",
    "#             "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "118c53e54622fc53",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# plt.figure(figsize=(10,10))\n",
    "# for i in range(4):\n",
    "#     plt.subplot(2,2,i+1)\n",
    "#     plt.title(dataset[i][1].item())\n",
    "#     plt.imshow(dataset[i][0].to('cpu').numpy().transpose((1,2,0)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:30:27.237575600Z",
     "start_time": "2024-05-12T20:30:27.198576100Z"
    }
   },
   "id": "e7c5729d47a50b5d",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class BirdSongClassifier(nn.Module):\n",
    "    def __init__(self, num_classes_1 = 88 , num_classes_2 = 85):\n",
    "        super(BirdSongClassifier,self).__init__()\n",
    "        # backbone\n",
    "        self.conv1 = nn.Conv2d( in_channels=1, out_channels= 64 , kernel_size=3)\n",
    "        self.norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d((3,3))\n",
    "        self.conv2 = nn.Conv2d( in_channels=64, out_channels=128 , kernel_size=3)\n",
    "        self.norm2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d((3,3))\n",
    "        self.conv3 = nn.Conv2d( in_channels=128, out_channels=64 , kernel_size=3)\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d((3,3))\n",
    "        \n",
    "        # multilabel classification for name \n",
    "        \n",
    "        self.names_l1 = nn.Linear(64*3*3 ,512 )\n",
    "        self.names_relu1 = nn.ReLU()\n",
    "        self.names_l2 = nn.Linear(512 , num_classes_1 )\n",
    "        \n",
    "        # multilabel classification for species       \n",
    "        \n",
    "        self.species_l1 = nn.Linear(64*3*3 ,512 )\n",
    "        self.species_relu1 = nn.ReLU()\n",
    "        self.species_l2 = nn.Linear(512 , num_classes_2 )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.relu3(x)\n",
    "        backbone = self.pool3(x)\n",
    "        # print(\"Backbone Shape : \", backbone.size())\n",
    "        #forward for names\n",
    "        x1 = backbone.view(-1, 64*3*3)\n",
    "        x1 = self.names_l1(x1.reshape(-1,64*3*3))\n",
    "        x1 = self.names_relu1(x1)\n",
    "        x1 = self.names_l2(x1)\n",
    "        # print(\"Name Head Shape = \" ,x1.shape)\n",
    "\n",
    "        #forward for species\n",
    "\n",
    "        x2 = backbone.view(-1, backbone.size(0) * backbone.size(1) * backbone.size(2) * backbone.size(3))\n",
    "        x2 = self.species_l1(x2.reshape(-1,backbone.size(0) * backbone.size(1) * backbone.size(2) * backbone.size(3)))\n",
    "        x2 = self.species_relu1(x2)\n",
    "        x2 = self.species_l2(x2)\n",
    "        return x1  ,x2\n",
    "\n",
    "    def test_model(self, data_loader):\n",
    "        \"\"\"\n",
    "        Test a model on a specified dataset.\n",
    "    \n",
    "        Inputs:\n",
    "            net - Trained model of type BaseNetwork\n",
    "            data_loader - DataLoader object of the dataset to test on (validation or test)\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        self.to(\"cuda\")\n",
    "        true_preds_names, true_preds_species,  count = 0., 0.0, 0\n",
    "        \n",
    "        for imgs, names , species in data_loader: \n",
    "            imgs, names , species = imgs.to(\"cuda\"), names.to(\"cuda\") , species.to(\"cuda\")\n",
    "            with torch.no_grad():\n",
    "                preds = self(imgs)\n",
    "                preds_names = preds[0].argmax(dim=-1)\n",
    "                preds_species = preds[1].argmax(dim=-1)\n",
    "                true_preds_names += (preds_names == names )[0].sum().item()\n",
    "                true_preds_species += (preds_species == species )[0].sum().item()\n",
    "                count += 2\n",
    "        test_acc = (true_preds_names +  true_preds_species) / count\n",
    "        return test_acc\n",
    "model = BirdSongClassifier()\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:35:20.851966500Z",
     "start_time": "2024-05-12T20:35:20.796966500Z"
    }
   },
   "id": "3e95fa90b7d66bff",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.007900677200902935"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "indices = torch.randperm(len(dataset))\n",
    "\n",
    "# Define the sizes of your desired splits\n",
    "train_size = int(0.6 * len(dataset))  # 60% of the data for training\n",
    "val_size = int(0.25 * len(dataset))   # 25% of the data for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remaining data for testing\n",
    "\n",
    "# Use random_split with shuffled indices to create the splits\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "batch_size = 1\n",
    "# You can then create data loaders for each split if needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, )\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model.test_model( test_loader )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:35:23.464755Z",
     "start_time": "2024-05-12T20:35:22.082685900Z"
    }
   },
   "id": "5486d021743b429a",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss : 16030.548892 , Train Acc : 0.0079, Val Acc : 0.00677507\n",
      "Epoch [2/1000], Training Loss : 15920.574944 , Train Acc : 0.0076, Val Acc : 0.00542005\n",
      "Epoch [3/1000], Training Loss : 15822.999226 , Train Acc : 0.0110, Val Acc : 0.00880759\n",
      "Epoch [4/1000], Training Loss : 15734.766327 , Train Acc : 0.0127, Val Acc : 0.00880759\n"
     ]
    }
   ],
   "source": [
    " import time\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion_names = nn.CrossEntropyLoss()\n",
    "criterion_species = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "model.to(\"cuda\")\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels_names, labels_species) in enumerate(train_loader):\n",
    "        \n",
    "        labels_names , labels_species = labels_names.to(\"cuda\") , labels_species.to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs_names , outputs_species = model(inputs.type(torch.cuda.FloatTensor))\n",
    "        # print(torch.argmax(outputs_names , dim=-1).item(), labels_names.item() ,\"-------\", torch.argmax(outputs_species , dim=-1).item(), labels_species.item())\n",
    "        # time.sleep(0.1)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss_names = criterion_names(outputs_names, labels_names.type(torch.cuda.LongTensor) )\n",
    "        loss_species = criterion_species(outputs_species, labels_species.type(torch.cuda.LongTensor))\n",
    "        t_loss_names = loss_names \n",
    "        t_loss_species = loss_species\n",
    "        total_loss = loss_names + loss_species\n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        # t_loss_species.backward(retain_graph= True)\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # optimizer_species.step()\n",
    "        running_loss += total_loss.item()\n",
    "        # running_loss_species += t_loss_species.item()\n",
    "        \n",
    "        # Print statistics every 100 batches\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        train_acc = model.test_model(train_loader) \n",
    "        val_acc = model.test_model(val_loader)\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss : {running_loss :.6f} , Train Acc : {train_acc:.4f}, Val Acc : {val_acc:.8f}')\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-12T20:35:27.107119600Z"
    }
   },
   "id": "66ceadb4427a31cc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': num_epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, \"epoch_1000_ta_79_va_67.pt\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:13:58.283314300Z",
     "start_time": "2024-05-12T11:13:58.163312700Z"
    }
   },
   "id": "bb5afab1664033cb",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "BirdSongClassifier(\n  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n  (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu1): ReLU()\n  (pool1): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu2): ReLU()\n  (pool2): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n  (norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu3): ReLU()\n  (pool3): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n  (names_l1): Linear(in_features=768, out_features=512, bias=True)\n  (names_relu1): ReLU()\n  (names_l2): Linear(in_features=512, out_features=88, bias=True)\n  (species_l1): Linear(in_features=768, out_features=512, bias=True)\n  (species_relu1): ReLU()\n  (species_l2): Linear(in_features=512, out_features=85, bias=True)\n)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model_ft = BirdSongClassifier()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.00001)\n",
    "\n",
    "checkpoint = torch.load(\"epoch_1000_ta_79_va_67.pt\" , map_location= device)\n",
    "model_ft.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_ft.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "model_ft.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:19:21.640327200Z",
     "start_time": "2024-05-12T11:19:21.512818500Z"
    }
   },
   "id": "ff7b42498b442992",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss : 1561.648120 , Train Acc : 0.8114, Val Acc : 0.69710145\n",
      "Epoch [2/1000], Training Loss : 1564.701713 , Train Acc : 0.8271, Val Acc : 0.69565217\n",
      "Epoch [3/1000], Training Loss : 1572.912654 , Train Acc : 0.8204, Val Acc : 0.68115942\n",
      "Epoch [4/1000], Training Loss : 1566.559977 , Train Acc : 0.8295, Val Acc : 0.69130435\n",
      "Epoch [5/1000], Training Loss : 1568.844399 , Train Acc : 0.8126, Val Acc : 0.68405797\n",
      "Epoch [6/1000], Training Loss : 1569.589457 , Train Acc : 0.8222, Val Acc : 0.71739130\n",
      "Epoch [7/1000], Training Loss : 1573.738139 , Train Acc : 0.8035, Val Acc : 0.70869565\n",
      "Epoch [8/1000], Training Loss : 1571.554301 , Train Acc : 0.8235, Val Acc : 0.67101449\n",
      "Epoch [9/1000], Training Loss : 1572.467697 , Train Acc : 0.8047, Val Acc : 0.69420290\n",
      "Epoch [10/1000], Training Loss : 1570.607854 , Train Acc : 0.8265, Val Acc : 0.65797101\n",
      "Epoch [11/1000], Training Loss : 1573.262043 , Train Acc : 0.8253, Val Acc : 0.70724638\n",
      "Epoch [12/1000], Training Loss : 1568.076810 , Train Acc : 0.8229, Val Acc : 0.69855072\n",
      "Epoch [13/1000], Training Loss : 1591.035042 , Train Acc : 0.8096, Val Acc : 0.66086957\n",
      "Epoch [14/1000], Training Loss : 1579.396460 , Train Acc : 0.8325, Val Acc : 0.71159420\n",
      "Epoch [15/1000], Training Loss : 1569.430825 , Train Acc : 0.8277, Val Acc : 0.75652174\n",
      "Epoch [16/1000], Training Loss : 1565.940758 , Train Acc : 0.8114, Val Acc : 0.67681159\n",
      "Epoch [17/1000], Training Loss : 1567.953907 , Train Acc : 0.8053, Val Acc : 0.67536232\n",
      "Epoch [18/1000], Training Loss : 1572.607306 , Train Acc : 0.8283, Val Acc : 0.68115942\n",
      "Epoch [19/1000], Training Loss : 1571.825837 , Train Acc : 0.8216, Val Acc : 0.68550725\n",
      "Epoch [20/1000], Training Loss : 1575.257034 , Train Acc : 0.8180, Val Acc : 0.71014493\n",
      "Epoch [21/1000], Training Loss : 1574.895281 , Train Acc : 0.8096, Val Acc : 0.67826087\n",
      "Epoch [22/1000], Training Loss : 1569.316867 , Train Acc : 0.8059, Val Acc : 0.70289855\n",
      "Epoch [23/1000], Training Loss : 1576.217213 , Train Acc : 0.8349, Val Acc : 0.70434783\n",
      "Epoch [24/1000], Training Loss : 1559.402718 , Train Acc : 0.8216, Val Acc : 0.71449275\n",
      "Epoch [25/1000], Training Loss : 1570.138724 , Train Acc : 0.8065, Val Acc : 0.67536232\n",
      "Epoch [26/1000], Training Loss : 1588.627442 , Train Acc : 0.8089, Val Acc : 0.66231884\n",
      "Epoch [27/1000], Training Loss : 1579.978464 , Train Acc : 0.8138, Val Acc : 0.67536232\n",
      "Epoch [28/1000], Training Loss : 1582.629030 , Train Acc : 0.8053, Val Acc : 0.71594203\n",
      "Epoch [29/1000], Training Loss : 1579.322845 , Train Acc : 0.8144, Val Acc : 0.70000000\n",
      "Epoch [30/1000], Training Loss : 1564.201590 , Train Acc : 0.8247, Val Acc : 0.65072464\n",
      "Epoch [31/1000], Training Loss : 1578.402048 , Train Acc : 0.8380, Val Acc : 0.71014493\n",
      "Epoch [32/1000], Training Loss : 1583.833753 , Train Acc : 0.8077, Val Acc : 0.72028986\n",
      "Epoch [33/1000], Training Loss : 1574.636914 , Train Acc : 0.8277, Val Acc : 0.70289855\n",
      "Epoch [34/1000], Training Loss : 1585.283415 , Train Acc : 0.8053, Val Acc : 0.70579710\n",
      "Epoch [35/1000], Training Loss : 1565.066564 , Train Acc : 0.8180, Val Acc : 0.69275362\n",
      "Epoch [36/1000], Training Loss : 1580.725818 , Train Acc : 0.8023, Val Acc : 0.69855072\n",
      "Epoch [37/1000], Training Loss : 1574.579136 , Train Acc : 0.8241, Val Acc : 0.72173913\n",
      "Epoch [38/1000], Training Loss : 1567.010051 , Train Acc : 0.8283, Val Acc : 0.70000000\n",
      "Epoch [39/1000], Training Loss : 1560.446563 , Train Acc : 0.8319, Val Acc : 0.67246377\n",
      "Epoch [40/1000], Training Loss : 1576.071882 , Train Acc : 0.8011, Val Acc : 0.65362319\n",
      "Epoch [41/1000], Training Loss : 1573.121008 , Train Acc : 0.8132, Val Acc : 0.68840580\n",
      "Epoch [42/1000], Training Loss : 1572.144203 , Train Acc : 0.8102, Val Acc : 0.67826087\n",
      "Epoch [43/1000], Training Loss : 1585.478789 , Train Acc : 0.8428, Val Acc : 0.69275362\n",
      "Epoch [44/1000], Training Loss : 1577.299048 , Train Acc : 0.8319, Val Acc : 0.70000000\n",
      "Epoch [45/1000], Training Loss : 1558.481315 , Train Acc : 0.8235, Val Acc : 0.68260870\n",
      "Epoch [46/1000], Training Loss : 1570.647271 , Train Acc : 0.8210, Val Acc : 0.71014493\n",
      "Epoch [47/1000], Training Loss : 1595.205945 , Train Acc : 0.8150, Val Acc : 0.68260870\n",
      "Epoch [48/1000], Training Loss : 1572.425036 , Train Acc : 0.8138, Val Acc : 0.68985507\n",
      "Epoch [49/1000], Training Loss : 1572.256885 , Train Acc : 0.8289, Val Acc : 0.70579710\n",
      "Epoch [50/1000], Training Loss : 1572.815823 , Train Acc : 0.8210, Val Acc : 0.70144928\n",
      "Epoch [51/1000], Training Loss : 1574.936467 , Train Acc : 0.8210, Val Acc : 0.72608696\n",
      "Epoch [52/1000], Training Loss : 1566.815621 , Train Acc : 0.8083, Val Acc : 0.69420290\n",
      "Epoch [53/1000], Training Loss : 1592.871616 , Train Acc : 0.8192, Val Acc : 0.67971014\n",
      "Epoch [54/1000], Training Loss : 1573.407919 , Train Acc : 0.8222, Val Acc : 0.68405797\n",
      "Epoch [55/1000], Training Loss : 1569.961860 , Train Acc : 0.8083, Val Acc : 0.71884058\n",
      "Epoch [56/1000], Training Loss : 1569.548523 , Train Acc : 0.8289, Val Acc : 0.70000000\n",
      "Epoch [57/1000], Training Loss : 1565.235868 , Train Acc : 0.8059, Val Acc : 0.68550725\n",
      "Epoch [58/1000], Training Loss : 1580.126524 , Train Acc : 0.8083, Val Acc : 0.64782609\n",
      "Epoch [59/1000], Training Loss : 1571.934204 , Train Acc : 0.8235, Val Acc : 0.66666667\n",
      "Epoch [60/1000], Training Loss : 1564.476824 , Train Acc : 0.8065, Val Acc : 0.71014493\n",
      "Epoch [61/1000], Training Loss : 1556.487019 , Train Acc : 0.8265, Val Acc : 0.69565217\n",
      "Epoch [62/1000], Training Loss : 1549.547954 , Train Acc : 0.8192, Val Acc : 0.68115942\n",
      "Epoch [63/1000], Training Loss : 1593.339707 , Train Acc : 0.8204, Val Acc : 0.65507246\n",
      "Epoch [64/1000], Training Loss : 1569.241345 , Train Acc : 0.8265, Val Acc : 0.67826087\n",
      "Epoch [65/1000], Training Loss : 1572.174818 , Train Acc : 0.8259, Val Acc : 0.69420290\n",
      "Epoch [66/1000], Training Loss : 1574.376048 , Train Acc : 0.7969, Val Acc : 0.68985507\n",
      "Epoch [67/1000], Training Loss : 1570.253027 , Train Acc : 0.8126, Val Acc : 0.67536232\n",
      "Epoch [68/1000], Training Loss : 1574.859779 , Train Acc : 0.8241, Val Acc : 0.67971014\n",
      "Epoch [69/1000], Training Loss : 1574.530396 , Train Acc : 0.8331, Val Acc : 0.70144928\n",
      "Epoch [70/1000], Training Loss : 1562.712349 , Train Acc : 0.8241, Val Acc : 0.67536232\n",
      "Epoch [71/1000], Training Loss : 1573.068707 , Train Acc : 0.8295, Val Acc : 0.69855072\n",
      "Epoch [72/1000], Training Loss : 1588.363973 , Train Acc : 0.8156, Val Acc : 0.70724638\n",
      "Epoch [73/1000], Training Loss : 1563.098006 , Train Acc : 0.8174, Val Acc : 0.69420290\n",
      "Epoch [74/1000], Training Loss : 1570.811988 , Train Acc : 0.8065, Val Acc : 0.70289855\n",
      "Epoch [75/1000], Training Loss : 1563.412020 , Train Acc : 0.7969, Val Acc : 0.70724638\n",
      "Epoch [76/1000], Training Loss : 1586.595148 , Train Acc : 0.8144, Val Acc : 0.70869565\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m outputs_names , outputs_species \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_ft\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFloatTensor\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# print(torch.argmax(outputs_names , dim=-1).item(), labels_names.item() ,\"-------\", torch.argmax(outputs_species , dim=-1).item(), labels_species.item())\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# time.sleep(0.1)\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Calculate loss\u001B[39;00m\n\u001B[0;32m     15\u001B[0m loss_names \u001B[38;5;241m=\u001B[39m criterion_names(outputs_names, labels_names\u001B[38;5;241m.\u001B[39mtype(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mLongTensor) )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\BirdSongClassification_20240502\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[13], line 51\u001B[0m, in \u001B[0;36mBirdSongClassifier.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     49\u001B[0m x1 \u001B[38;5;241m=\u001B[39m backbone\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, backbone\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m*\u001B[39m backbone\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m backbone\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m     50\u001B[0m x1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnames_l1(x1\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m768\u001B[39m))\n\u001B[1;32m---> 51\u001B[0m x1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnames_relu1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m x1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnames_l2(x1)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# print(\"Name Head Shape = \" ,x1.shape)\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m#forward for species\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\BirdSongClassification_20240502\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\BirdSongClassification_20240502\\lib\\site-packages\\torch\\nn\\modules\\activation.py:103\u001B[0m, in \u001B[0;36mReLU.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\BirdSongClassification_20240502\\lib\\site-packages\\torch\\nn\\functional.py:1457\u001B[0m, in \u001B[0;36mrelu\u001B[1;34m(input, inplace)\u001B[0m\n\u001B[0;32m   1455\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu_(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1457\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1458\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model_ft.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels_names, labels_species) in enumerate(train_loader):\n",
    "        \n",
    "        labels_names , labels_species = labels_names.to(\"cuda\") , labels_species.to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs_names , outputs_species = model_ft(inputs.type(torch.cuda.FloatTensor))\n",
    "        # print(torch.argmax(outputs_names , dim=-1).item(), labels_names.item() ,\"-------\", torch.argmax(outputs_species , dim=-1).item(), labels_species.item())\n",
    "        # time.sleep(0.1)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss_names = criterion_names(outputs_names, labels_names.type(torch.cuda.LongTensor) )\n",
    "        loss_species = criterion_species(outputs_species, labels_species.type(torch.cuda.LongTensor))\n",
    "        t_loss_names = loss_names \n",
    "        t_loss_species = loss_species\n",
    "        total_loss = loss_names + loss_species\n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        # t_loss_species.backward(retain_graph= True)\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # optimizer_species.step()\n",
    "        running_loss += total_loss.item()\n",
    "        # running_loss_species += t_loss_species.item()\n",
    "        \n",
    "        # Print statistics every 100 batches\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        train_acc = model_ft.test_model(train_loader) \n",
    "        val_acc = model_ft.test_model(val_loader)\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss : {running_loss :.6f} , Train Acc : {train_acc:.4f}, Val Acc : {val_acc:.8f}')\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:23:08.376324800Z",
     "start_time": "2024-05-12T11:19:26.822759100Z"
    }
   },
   "id": "55f36732b6457773"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4068e632cb43ac38"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
